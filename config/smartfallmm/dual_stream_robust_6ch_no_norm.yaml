# DualStreamRobust with No Normalization (6ch)
#
# SE Normalization Comparison Experiment
# Model: DualStreamRobust (SE + CrossModalGate + TemporalAttention)
# Normalization: DISABLED
#
# Architecture (~18K params):
# - ACC stream: DepthwiseSeparableConv -> Transformer -> SE -> TemporalAttention
# - GYRO stream: DepthwiseSeparableConv -> SE -> MLP -> MeanPool
# - Fusion: CrossModalGate -> concat -> MLP -> classifier

model: Models.dual_stream_robust.DualStreamRobust
dataset: smartfallmm

subjects: [29,30,31,32,34,35,36,37,38,39,43,44,45,46,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63]
validation_subjects: [48, 57]
train_only_subjects: [29, 30, 32, 35, 39, 59]

model_args:
  imu_channels: 6
  acc_coords: 6
  imu_frames: 128
  acc_frames: 128
  mocap_frames: 128
  num_joints: 32
  acc_dim: 48
  gyro_dim: 16
  num_heads: 4
  num_layers: 1
  dropout: 0.5
  acc_dropout: 0.3
  gyro_dropout: 0.5
  num_classes: 1
  use_se: True
  use_temporal_attention: True
  use_cross_modal_gate: True
  activation: gelu
  norm_first: True

dataset_args:
  mode: sliding_window
  max_length: 128
  task: fd
  modalities: [accelerometer, gyroscope]
  age_group: [young]
  sensors: [watch]
  use_skeleton: False
  stride: 32

  # 6 channels: no SMV
  include_smv: False
  include_gyro_mag: False

  # Simple truncation for alignment
  enable_simple_truncation: True
  max_truncation_diff: 50
  enable_timestamp_alignment: False
  enable_gyro_alignment: False

  # NORMALIZATION DISABLED
  enable_normalization: False

  # Preprocessing
  enable_filtering: False
  convert_gyro_to_rad: True

  # Class-aware stride
  enable_class_aware_stride: True
  fall_stride: 16
  adl_stride: 32

  # Disable legacy options
  discard_mismatched_modalities: False
  length_sensitive_modalities: [accelerometer, gyroscope]

batch_size: 64
test_batch_size: 64
val_batch_size: 64
num_epoch: 80
optimizer: adamw
base_lr: 1.0e-3
weight_decay: 1.0e-3
seed: 2

feeder: Feeder.Make_Dataset.UTD_mm
train_feeder_args:
  batch_size: 64
val_feeder_args:
  batch_size: 64
test_feeder_args:
  batch_size: 64
